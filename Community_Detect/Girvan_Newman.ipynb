{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "        def __init__(self, id):\n",
    "            self.id = id\n",
    "            self.level = float('inf')\n",
    "            self.label = 0\n",
    "            self.credit = 1\n",
    "\n",
    "class Tree:\n",
    "    def __init__(self, root, node_list, neighbors_map):\n",
    "        self.node_list = {node:Node(node) for node in node_list}\n",
    "        self.root = self.node_list[root]\n",
    "        self.edge_credit = set()\n",
    "        self.neighbors_map = neighbors_map\n",
    "\n",
    "    def gen_edges_credit(self):\n",
    "        self.root.level = 0\n",
    "        self.root.label = 1\n",
    "        queue = [self.root]\n",
    "        while queue:\n",
    "            node = queue.pop(0)\n",
    "            for nb_id in self.neighbors_map[node.id]:\n",
    "                nb_node = self.node_list[nb_id]\n",
    "                if nb_node.level>node.level:\n",
    "                    nb_node.level = node.level+1\n",
    "                    nb_node.label += node.label\n",
    "                    queue.append(nb_node)\n",
    "        return [(node.id,node.label) for node in self.node_list.values()]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cmp(key1, key2):\n",
    "    \"\"\"\n",
    "    :param key1:\n",
    "    :param key2:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return (key1, key2) if key1 < key2 else (key2, key1)\n",
    "\n",
    "\n",
    "def export2File(result_array, file_path):\n",
    "    \"\"\"\n",
    "    export list content to a file\n",
    "    :param result_array: a list of dict\n",
    "    :param file_path: output file path\n",
    "    :return: nothing, but a file\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w+') as output_file:\n",
    "        for id_array in result_array:\n",
    "            output_file.writelines(str(id_array)[1:-1] + \"\\n\")\n",
    "        output_file.close()\n",
    "\n",
    "\n",
    "def update_dict(dict_obj, key, increment):\n",
    "    \"\"\"\n",
    "    update the value with the same key, rather than replace it\n",
    "    :param dict_obj:\n",
    "    :param key:\n",
    "    :param increment:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    old_weight = dict_obj[key]\n",
    "    dict_obj[key] = float(old_weight + increment)\n",
    "    return dict_obj\n",
    "\n",
    "\n",
    "def extend_dict(dict_obj, increment_dict):\n",
    "    \"\"\"\n",
    "    same as list extend\n",
    "    :param dict_obj:\n",
    "    :param increment_dict:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for key, value in increment_dict.items():\n",
    "        if key in dict_obj.keys():\n",
    "            dict_obj = update_dict(dict_obj, key, value)\n",
    "        else:\n",
    "            dict_obj[key] = value\n",
    "    return dict_obj\n",
    "class GraphFrame(object):\n",
    "\n",
    "    def __init__(self, vertexes, edges):\n",
    "        \"\"\"\n",
    "        :param vertexes: list of vertexes [1,2,3,4...]\n",
    "        :param edges: a big dict(vertex: (list of vertex it connected)\n",
    "        \"\"\"\n",
    "        self.vertexes = vertexes\n",
    "        self.vertex_weight_dict = dict()\n",
    "        self.__init_weight_dict__()\n",
    "\n",
    "        self.edges = edges\n",
    "        self.__init_adjacent_matrix__(edges)\n",
    "\n",
    "        # variable using for compute betweenness\n",
    "        self.betweenness_result_dict = dict()\n",
    "        self.betweenness_result_tuple_list = None\n",
    "\n",
    "        # variable using for compute modularity\n",
    "        self.best_communities = None\n",
    "\n",
    "    def __init_weight_dict__(self):\n",
    "        [self.vertex_weight_dict.setdefault(vertex, 1) for vertex in self.vertexes]\n",
    "\n",
    "    def __init_adjacent_matrix__(self, edges):\n",
    "        \"\"\"\n",
    "        build a set which contain all edge pair\n",
    "        :param edges: original edges (a big dict (vertex: [list of vertex it connected]))\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.original_edges = edges\n",
    "        self.m = self._count_edges(edges)\n",
    "\n",
    "        # build adjacent matrix for original edges\n",
    "        edge_set = set()\n",
    "        for start_node, end_nodes in edges.items():\n",
    "            for end_node in end_nodes:\n",
    "                edge_set.add(cmp(start_node, end_node))\n",
    "        self.A_matrix = edge_set\n",
    "\n",
    "    def _count_edges(self, edges):\n",
    "        \"\"\"\n",
    "        :param edges:  a big dict(vertex: (list of vertex it connected)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        visited = set()\n",
    "        count = 0\n",
    "        for start_node, end_nodes in edges.items():\n",
    "            for end_node in end_nodes:\n",
    "                key = cmp(start_node, end_node)\n",
    "                if key not in visited:\n",
    "                    visited.add(key)\n",
    "                    count += 1\n",
    "        return count\n",
    "\n",
    "    def _build_tree(self, root):\n",
    "        # root set in level 0 and no parent\n",
    "        print(root)\n",
    "        tree = dict()\n",
    "        tree[root] = (0, list())\n",
    "\n",
    "        # since BFS only visit each node once,\n",
    "        # so use visited variable to save these records\n",
    "        visited = set()\n",
    "\n",
    "        need2visit = list()\n",
    "        need2visit.append(root)\n",
    "\n",
    "        while len(need2visit) > 0:\n",
    "            parent_node = need2visit.pop(0)\n",
    "            visited.add(parent_node)\n",
    "            for children in self.edges[parent_node]:\n",
    "                if children not in visited:\n",
    "                    visited.add(children)\n",
    "                    tree[children] = (tree[parent_node][0] + 1, [parent_node])\n",
    "                    need2visit.append(children)\n",
    "                elif tree[parent_node][0] + 1 == tree[children][0]:\n",
    "                    tree[children][1].append(parent_node)\n",
    "\n",
    "        return {k: v for k, v in sorted(tree.items(), key=lambda kv: -kv[1][0])}\n",
    "\n",
    "    def _traverse_tree(self, tree_dict):\n",
    "        \"\"\"\n",
    "        traverse the tree and compute weight for each edge\n",
    "        :param tree_dict: {'2GUjO7NU88cPXpoffYCU8w': (9, ['a48HhwcmjFLApZhiax41IA']), ...\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        weight_dict = self.vertex_weight_dict.copy()\n",
    "        shortest_path_dict = self._find_num_of_paths(tree_dict)\n",
    "        result_dict = dict()\n",
    "        for key, value in tree_dict.items():\n",
    "            if len(value[1]) > 0:\n",
    "                denominator = sum([shortest_path_dict[parent] for parent in value[1]])\n",
    "                for parent in value[1]:\n",
    "                    temp_key = cmp(key, parent)\n",
    "                    contribution = float(float(weight_dict[key]) * int(shortest_path_dict[parent]) / denominator)\n",
    "                    result_dict[temp_key] = contribution\n",
    "                    # update every parent node weight\n",
    "                    weight_dict = update_dict(weight_dict, parent, contribution)\n",
    "\n",
    "        return result_dict\n",
    "\n",
    "    def _find_num_of_paths(self, tree_dict):\n",
    "        \"\"\"\n",
    "        find how many the number of shortest path each node has\n",
    "        :param tree_dict: {'2GUjO7NU88cPXpoffYCU8w': (9, ['a48HhwcmjFLApZhiax41IA']), ...\n",
    "        :return: {'y6jsaAXFstAJkf53R4_y4Q': 1, '0FVcoJko1kfZCrJRfssfIA': 1, '2quguRdKBzul ...\n",
    "        \"\"\"\n",
    "        level_dict = dict()\n",
    "        shortest_path_dict = dict()\n",
    "        for child_node, level_parents in tree_dict.items():\n",
    "            level_dict.setdefault(level_parents[0], []) \\\n",
    "                .append((child_node, level_parents[1]))\n",
    "\n",
    "        for level in range(0, len(level_dict.keys())):\n",
    "            for (child_node, parent_node_list) in level_dict[level]:\n",
    "                if len(parent_node_list) > 0:\n",
    "                    shortest_path_dict[child_node] = sum([shortest_path_dict[parent]\n",
    "                                                          for parent in parent_node_list])\n",
    "                else:\n",
    "                    shortest_path_dict[child_node] = 1\n",
    "        return shortest_path_dict\n",
    "\n",
    "    def computeBetweenness(self):\n",
    "        \"\"\"\n",
    "        compute betweenness of each edge pair\n",
    "        :return: list of tuple(pair, float)\n",
    "                => e.g. [(('0FVcoJko1kfZCrJRfssfIA', 'bbK1mL-AyYCHZncDQ_4RgA'), 189.0), ...\n",
    "        \"\"\"\n",
    "        self.betweenness_result_dict = dict()\n",
    "        for node in self.vertexes:\n",
    "            # 1.The algorithm begins by performing a breadth-first search\n",
    "            # (BFS) of the graph, starting at the vertex X in all vertexes list\n",
    "            # =>{'2GUjO7NU88cPXpoffYCU8w': (9, ['a48HhwcmjFLApZhiax41IA']),\n",
    "            # '6YmRpoIuiq8I19Q8dHKTHw': (9, ['a48Hh\n",
    "            bfs_tree = self._build_tree(root=node)\n",
    "            # 2. Label each node by the number of shortest\n",
    "            # paths that reach it from the root node\n",
    "            # actually, this step has been done in the first step,\n",
    "            # since the len of value[1] is exactly the number of shortest path\n",
    "            # 3. Calculate for each edge e, the sum over all nodes\n",
    "            # Y (of the fraction) of the shortest paths from the root\n",
    "            # X to Y that go through edge e\n",
    "            temp_result_dict = self._traverse_tree(bfs_tree)\n",
    "\n",
    "            self.betweenness_result_dict = extend_dict(self.betweenness_result_dict,\n",
    "                                                       temp_result_dict)\n",
    "\n",
    "        # 4. Divide by 2 to get true betweenness\n",
    "        self.betweenness_result_dict = \\\n",
    "            dict(map(lambda kv: (kv[0], float(kv[1] / 2)),\n",
    "                     self.betweenness_result_dict.items()))\n",
    "\n",
    "        self.betweenness_result_tuple_list = sorted(\n",
    "            self.betweenness_result_dict.items(), key=lambda kv: (-kv[1], kv[0][0]))\n",
    "        return self.betweenness_result_tuple_list\n",
    "\n",
    "    def extractCommunities(self):\n",
    "        \"\"\"\n",
    "        extract communities from butch of edge pairs\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        max_modularity = float(\"-inf\")\n",
    "        # reuse the betweenness dict\n",
    "        if len(self.betweenness_result_tuple_list) > 0:\n",
    "            # cut edges with highest betweenness\n",
    "            self._cut_highest_btw_edge(self.betweenness_result_tuple_list)\n",
    "            self.best_communities, max_modularity = self._computeModularity()\n",
    "            # recompute and update self.betweenness_result_tuple_list\n",
    "            self.betweenness_result_tuple_list = self.computeBetweenness()\n",
    "\n",
    "        while True:\n",
    "            # cut edges with highest betweenness\n",
    "            self._cut_highest_btw_edge(self.betweenness_result_tuple_list)\n",
    "            communities, current_modularity = self._computeModularity()\n",
    "            self.betweenness_result_tuple_list = self.computeBetweenness()\n",
    "            if current_modularity < max_modularity:\n",
    "                # break when elbow point shows\n",
    "                break\n",
    "            else:\n",
    "                # when current_modularity > max_modularity happens:\n",
    "                # we still need to cut the edges\n",
    "                self.best_communities = communities\n",
    "                max_modularity = current_modularity\n",
    "\n",
    "        return sorted(self.best_communities, key=lambda item: (len(item), item[0], item[1]))\n",
    "\n",
    "    def _cut_highest_btw_edge(self, edge_btw_tuple_list):\n",
    "        \"\"\"\n",
    "        remove edges with highest betweenness and also update the self.edges\n",
    "        :param edge_btw_tuple_list: need to be a [sorted] list, sorted by value\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # this is the edge you need to cut\n",
    "        temp_value = 0\n",
    "        # if there have multiple pair have same highest bet score,\n",
    "        # we cut them in one loop\n",
    "        edge_pair = edge_btw_tuple_list[0][0]\n",
    "\n",
    "        if self.edges[edge_pair[0]] is not None:\n",
    "            try:\n",
    "                self.edges[edge_pair[0]].remove(edge_pair[1])\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        if self.edges[edge_pair[1]] is not None:\n",
    "            try:\n",
    "                self.edges[edge_pair[1]].remove(edge_pair[0])\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    def _computeModularity(self):\n",
    "        \"\"\"\n",
    "        compute the modularity based on communities we get\n",
    "        :return: a list of communities and a float number => modularity\n",
    "        \"\"\"\n",
    "\n",
    "        # 1. detect communities from current edge_pairs\n",
    "        communities = self._detectCommunities()\n",
    "\n",
    "        # 2. compute modularity based on the communities\n",
    "        # 2.1 count original graph's edge number => self.m\n",
    "        # 2.2 build adjacent matrix => self.A_matrix\n",
    "        temp_sum = 0\n",
    "        for cluster in communities:\n",
    "            for node_pair in itertools.combinations(list(cluster), 2):\n",
    "                temp_key = cmp(node_pair[0], node_pair[1])\n",
    "                k_i = len(self.edges[node_pair[0]])\n",
    "                k_j = len(self.edges[node_pair[1]])\n",
    "                A = 1 if temp_key in self.A_matrix else 0\n",
    "                temp_sum += float(A - (k_i * k_j / (2 * self.m)))\n",
    "        return communities, float(temp_sum / (2 * self.m))\n",
    "\n",
    "    def _detectCommunities(self):\n",
    "        \"\"\"\n",
    "        detect communities based on self.edge\n",
    "        basically, we randomly pick one root and find all connected node with root\n",
    "        and then do the same thing on the rest of node\n",
    "        :return: a list of set() which contain communities\n",
    "        \"\"\"\n",
    "        communities = list()  # result will be return\n",
    "        need2visit = list()  # a stack actually\n",
    "        temp_node_set = set()  # using to save each communities\n",
    "        visited = set()  # track which node has been visited\n",
    "\n",
    "        # random pick a root to detect communities\n",
    "        random_root = self.vertexes[random.randint(0, len(self.vertexes) - 1)]\n",
    "        temp_node_set.add(random_root)\n",
    "        need2visit.append(random_root)\n",
    "        # if still has some node we haven't visit, do the loop\n",
    "        while len(visited) != len(self.vertexes):\n",
    "            while len(need2visit) > 0:\n",
    "                parent_node = need2visit.pop(0)\n",
    "                temp_node_set.add(parent_node)\n",
    "                visited.add(parent_node)\n",
    "                for children in self.edges[parent_node]:\n",
    "                    if children not in visited:\n",
    "                        temp_node_set.add(children)\n",
    "                        need2visit.append(children)\n",
    "                        visited.add(children)\n",
    "\n",
    "            communities.append(sorted(temp_node_set))\n",
    "            temp_node_set = set()\n",
    "            if len(self.vertexes) > len(visited):\n",
    "                # pick one from rest of unvisited nodes\n",
    "                need2visit.append(set(self.vertexes).difference(visited).pop())\n",
    "\n",
    "        return communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n",
      "D\n",
      "E\n",
      "F\n",
      "G\n",
      "[(('B', 'D'), 12.0), (('A', 'B'), 5.0), (('B', 'C'), 5.0), (('D', 'G'), 4.5), (('D', 'E'), 4.5), (('D', 'F'), 4.0), (('E', 'F'), 1.5), (('F', 'G'), 1.5), (('A', 'C'), 1.0)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('B', 'D'), 12.0),\n",
       " (('A', 'B'), 5.0),\n",
       " (('B', 'C'), 5.0),\n",
       " (('D', 'G'), 4.5),\n",
       " (('D', 'E'), 4.5),\n",
       " (('D', 'F'), 4.0),\n",
       " (('E', 'F'), 1.5),\n",
       " (('F', 'G'), 1.5),\n",
       " (('A', 'C'), 1.0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_frame = GraphFrame(nodes, neighbors_map)\n",
    "graph_frame.computeBetweenness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Girvan_Newman(x,nodes,neighbors_map):\n",
    "    root = x\n",
    "    nodes_level = {node:float('inf') for node in nodes}\n",
    "    nodes_label = {node:0 for node in nodes}\n",
    "    nodes_credit = {node:1 for node in nodes}\n",
    "\n",
    "    nodes_level[root] = 0\n",
    "    nodes_label[root] = 1\n",
    "    queue = [root]\n",
    "    visited = []\n",
    "    # Label\n",
    "    while queue:\n",
    "        cur_node = queue.pop(0)\n",
    "        visited.append(cur_node)\n",
    "        cur_node_level = nodes_level[cur_node]\n",
    "        cur_node_label = nodes_label[cur_node]\n",
    "        for nb_node in neighbors_map[cur_node]:\n",
    "            if nodes_level[nb_node]>cur_node_level:\n",
    "                nodes_level[nb_node] = cur_node_level+1\n",
    "                nodes_label[nb_node] += cur_node_label\n",
    "                if nb_node not in queue:\n",
    "                    queue.append(nb_node)\n",
    "    #Credit\n",
    "    result = []\n",
    "    while visited:\n",
    "        cur_node = visited.pop()\n",
    "        cur_node_level = nodes_level[cur_node]\n",
    "        cur_node_label = nodes_label[cur_node]\n",
    "        cur_node_credit = nodes_credit[cur_node]\n",
    "        for nb_node in neighbors_map[cur_node]:\n",
    "            if nodes_level[nb_node]<cur_node_level:\n",
    "                edge = tuple(sorted([cur_node,nb_node]))\n",
    "                edge_credit = nodes_label[nb_node]*cur_node_credit/cur_node_label\n",
    "                nodes_credit[nb_node] += edge_credit\n",
    "                result.append((edge,edge_credit))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors_map = {\n",
    "    \"A\":[\"B\",\"C\"],\n",
    "    \"B\":{\"A\",\"C\",\"D\"},\n",
    "    \"C\":{\"A\",\"B\"},\n",
    "    \"D\":{\"B\",\"G\",\"F\",\"E\"},\n",
    "    \"E\":{\"D\",\"F\"},\n",
    "    \"F\":{\"G\",\"D\",\"E\"},\n",
    "    \"G\":{\"D\",\"F\"}\n",
    "}\n",
    "\n",
    "nodes = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\"]\n",
    "\n",
    "edges = [{\"A\",\"B\"},{\"A\",\"C\"},{\"B\",\"C\"},{\"B\",\"D\"},{\"D\",\"E\"},{\"E\",\"F\"},{\"G\",\"F\"},{\"D\",\"F\"},{\"F\",\"G\"},{\"D\",\"G\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('D', 'E'): 1.0, ('D', 'G'): 1.0, ('D', 'F'): 1.0, ('B', 'D'): 4.0, ('A', 'B'): 5.0, ('A', 'C'): 1.0}\n",
      "{('D', 'E'): 1.0, ('D', 'G'): 1.0, ('D', 'F'): 1.0, ('B', 'D'): 4.0, ('B', 'C'): 1.0, ('A', 'B'): 1.0}\n",
      "{('D', 'E'): 1.0, ('D', 'G'): 1.0, ('D', 'F'): 1.0, ('B', 'D'): 4.0, ('B', 'C'): 5.0, ('A', 'C'): 1.0}\n",
      "{('B', 'C'): 1.0, ('A', 'B'): 1.0, ('B', 'D'): 3.0, ('D', 'E'): 1.0, ('D', 'G'): 1.0, ('D', 'F'): 1.0}\n",
      "{('B', 'C'): 1.0, ('A', 'B'): 1.0, ('B', 'D'): 3.0, ('F', 'G'): 0.5, ('D', 'G'): 0.5, ('D', 'E'): 4.5, ('E', 'F'): 1.5}\n",
      "{('B', 'C'): 1.0, ('A', 'B'): 1.0, ('B', 'D'): 3.0, ('D', 'F'): 4.0, ('F', 'G'): 1.0, ('E', 'F'): 1.0}\n",
      "{('B', 'C'): 1.0, ('A', 'B'): 1.0, ('B', 'D'): 3.0, ('E', 'F'): 0.5, ('D', 'E'): 0.5, ('D', 'G'): 4.5, ('F', 'G'): 1.5}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for root in nodes:\n",
    "    print(dict(Girvan_Newman(root,nodes,neighbors_map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytree = Tree(\"E\",nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytree.gen_edges_credit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 1), ('B', 1), ('C', 1), ('D', 1), ('E', 1), ('F', 1), ('G', 2)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(node.id,node.label) for node in mytree.node_list.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('newenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87ef2c4983d124858e7bc65373e634017d4d0da0a01665b9091a743c5bc24cc8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
